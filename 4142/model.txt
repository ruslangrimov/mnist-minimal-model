model.add(Conv2D(8, (3, 3), input_shape=input_shape, activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Conv2D(16, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Conv2D(16, (3, 1), activation='relu'))
model.add(BatchNormalization())
model.add(Conv2D(16, (1, 3), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Conv2D(4, (1, 1), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Flatten())
model.add(Dense(24, activation='relu'))
model.add(Dropout(rate=0.1))
model.add(Dense(10, activation='softmax'))

batch_size = 32
num_epochs = 50

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])


model.fit(x_train, y_train,
          batch_size=batch_size, epochs=num_epochs,
          verbose=1, validation_split=0.1,
          callbacks=[ModelCheckpoint('mini/weights.{epoch:02d}-{loss:.4f}-{acc:.4f}-{val_loss:.4f}-{val_acc:.4f}.hdf5',
                                     monitor='loss,acc,val_loss,val_acc')])


Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_116 (Conv2D)          (None, 26, 26, 8)         80        
_________________________________________________________________
max_pooling2d_57 (MaxPooling (None, 13, 13, 8)         0         
_________________________________________________________________
batch_normalization_116 (Bat (None, 13, 13, 8)         32        
_________________________________________________________________
dropout_73 (Dropout)         (None, 13, 13, 8)         0         
_________________________________________________________________
conv2d_117 (Conv2D)          (None, 11, 11, 16)        1168      
_________________________________________________________________
max_pooling2d_58 (MaxPooling (None, 5, 5, 16)          0         
_________________________________________________________________
batch_normalization_117 (Bat (None, 5, 5, 16)          64        
_________________________________________________________________
dropout_74 (Dropout)         (None, 5, 5, 16)          0         
_________________________________________________________________
conv2d_118 (Conv2D)          (None, 3, 5, 16)          784       
_________________________________________________________________
batch_normalization_118 (Bat (None, 3, 5, 16)          64        
_________________________________________________________________
conv2d_119 (Conv2D)          (None, 3, 3, 16)          784       
_________________________________________________________________
batch_normalization_119 (Bat (None, 3, 3, 16)          64        
_________________________________________________________________
dropout_75 (Dropout)         (None, 3, 3, 16)          0         
_________________________________________________________________
conv2d_120 (Conv2D)          (None, 3, 3, 4)           68        
_________________________________________________________________
batch_normalization_120 (Bat (None, 3, 3, 4)           16        
_________________________________________________________________
dropout_76 (Dropout)         (None, 3, 3, 4)           0         
_________________________________________________________________
flatten_29 (Flatten)         (None, 36)                0         
_________________________________________________________________
dense_60 (Dense)             (None, 24)                888       
_________________________________________________________________
dropout_77 (Dropout)         (None, 24)                0         
_________________________________________________________________
dense_61 (Dense)             (None, 10)                250       
=================================================================
Total params: 4,262
Trainable params: 4,142
Non-trainable params: 120


Test score:  0.0264436473006
Test accuracy:  0.9917
