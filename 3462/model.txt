model.add(Conv2D(8, (3, 3), input_shape=input_shape, activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Conv2D(12, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Conv2D(16, (3, 1), activation='relu'))
model.add(BatchNormalization())
model.add(Conv2D(16, (1, 3), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Conv2D(4, (1, 1), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Flatten())
model.add(Dense(20, activation='relu'))
model.add(Dropout(rate=0.1))
model.add(Dense(10, activation='softmax'))

batch_size = 32
num_epochs = 75

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])


model.fit(x_train, y_train,
          batch_size=batch_size, epochs=num_epochs,
          verbose=1, validation_split=0.1,
          callbacks=[ModelCheckpoint('mini/weights.{epoch:02d}-{loss:.4f}-{acc:.4f}-{val_loss:.4f}-{val_acc:.4f}.hdf5',
                                     monitor='loss,acc,val_loss,val_acc')])



Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_298 (Conv2D)          (None, 26, 26, 8)         80        
_________________________________________________________________
max_pooling2d_129 (MaxPoolin (None, 13, 13, 8)         0         
_________________________________________________________________
batch_normalization_296 (Bat (None, 13, 13, 8)         32        
_________________________________________________________________
dropout_253 (Dropout)        (None, 13, 13, 8)         0         
_________________________________________________________________
conv2d_299 (Conv2D)          (None, 11, 11, 12)        876       
_________________________________________________________________
max_pooling2d_130 (MaxPoolin (None, 5, 5, 12)          0         
_________________________________________________________________
batch_normalization_297 (Bat (None, 5, 5, 12)          48        
_________________________________________________________________
dropout_254 (Dropout)        (None, 5, 5, 12)          0         
_________________________________________________________________
conv2d_300 (Conv2D)          (None, 3, 5, 16)          592       
_________________________________________________________________
batch_normalization_298 (Bat (None, 3, 5, 16)          64        
_________________________________________________________________
conv2d_301 (Conv2D)          (None, 3, 3, 16)          784       
_________________________________________________________________
batch_normalization_299 (Bat (None, 3, 3, 16)          64        
_________________________________________________________________
dropout_255 (Dropout)        (None, 3, 3, 16)          0         
_________________________________________________________________
conv2d_302 (Conv2D)          (None, 3, 3, 4)           68        
_________________________________________________________________
batch_normalization_300 (Bat (None, 3, 3, 4)           16        
_________________________________________________________________
dropout_256 (Dropout)        (None, 3, 3, 4)           0         
_________________________________________________________________
flatten_65 (Flatten)         (None, 36)                0         
_________________________________________________________________
dense_132 (Dense)            (None, 20)                740       
_________________________________________________________________
dropout_257 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_133 (Dense)            (None, 10)                210       
=================================================================
Total params: 3,574
Trainable params: 3,462
Non-trainable params: 112


Test score:  0.0307938806147
Test accuracy:  0.9906
