model.add(Conv2D(8, (3, 3), input_shape=input_shape, activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Conv2D(12, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Conv2D(16, (3, 1), activation='relu'))
model.add(BatchNormalization())
model.add(Conv2D(16, (1, 3), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Conv2D(4, (1, 1), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(rate=0.1))
model.add(Flatten())
model.add(Dense(24, activation='relu'))
model.add(Dropout(rate=0.1))
model.add(Dense(10, activation='softmax'))

batch_size = 32
num_epochs = 50

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])


model.fit(x_train, y_train,
          batch_size=batch_size, epochs=num_epochs,
          verbose=1, validation_split=0.1,
          callbacks=[ModelCheckpoint('mini/weights.{epoch:02d}-{loss:.4f}-{acc:.4f}-{val_loss:.4f}-{val_acc:.4f}.hdf5',
                                     monitor='loss,acc,val_loss,val_acc')])



Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_153 (Conv2D)          (None, 26, 26, 8)         80        
_________________________________________________________________
max_pooling2d_71 (MaxPooling (None, 13, 13, 8)         0         
_________________________________________________________________
batch_normalization_151 (Bat (None, 13, 13, 8)         32        
_________________________________________________________________
dropout_108 (Dropout)        (None, 13, 13, 8)         0         
_________________________________________________________________
conv2d_154 (Conv2D)          (None, 11, 11, 12)        876       
_________________________________________________________________
max_pooling2d_72 (MaxPooling (None, 5, 5, 12)          0         
_________________________________________________________________
batch_normalization_152 (Bat (None, 5, 5, 12)          48        
_________________________________________________________________
dropout_109 (Dropout)        (None, 5, 5, 12)          0         
_________________________________________________________________
conv2d_155 (Conv2D)          (None, 3, 5, 16)          592       
_________________________________________________________________
batch_normalization_153 (Bat (None, 3, 5, 16)          64        
_________________________________________________________________
conv2d_156 (Conv2D)          (None, 3, 3, 16)          784       
_________________________________________________________________
batch_normalization_154 (Bat (None, 3, 3, 16)          64        
_________________________________________________________________
dropout_110 (Dropout)        (None, 3, 3, 16)          0         
_________________________________________________________________
conv2d_157 (Conv2D)          (None, 3, 3, 4)           68        
_________________________________________________________________
batch_normalization_155 (Bat (None, 3, 3, 4)           16        
_________________________________________________________________
dropout_111 (Dropout)        (None, 3, 3, 4)           0         
_________________________________________________________________
flatten_36 (Flatten)         (None, 36)                0         
_________________________________________________________________
dense_74 (Dense)             (None, 24)                888       
_________________________________________________________________
dropout_112 (Dropout)        (None, 24)                0         
_________________________________________________________________
dense_75 (Dense)             (None, 10)                250       
=================================================================
Total params: 3,762
Trainable params: 3,650
Non-trainable params: 112


Test score:  0.0323348842089
Test accuracy:  0.9905
