def dw_block(sh_l, prev_l):
    l = sh_l(prev_l)
    l = Activation(activation='relu')(l)
    l = BatchNormalization()(l)
    l = Dropout(rate=0.1)(l)
    return l
    
inputs = Input((28, 28, 1), dtype=np.float32)
l = inputs

l = Conv2D(8, (3, 3), input_shape=input_shape)(l)
l = Activation(activation='relu')(l)
l = BatchNormalization()(l)
l = MaxPooling2D((2, 2))(l)
l = Dropout(rate=0.1)(l)

l = SeparableConv2D(28, (3, 3), depth_multiplier=1)(l)
l = Activation(activation='relu')(l)
l = BatchNormalization()(l)
l = Dropout(rate=0.1)(l)

sh_l = SeparableConv2D(28, (3, 3), depth_multiplier=1, padding='same')

for n in range(3):
    l = dw_block(sh_l, l)

l = GlobalAveragePooling2D()(l)

l = Dense(16, activation='relu')(l)
l = BatchNormalization()(l)
l = Dropout(rate=0.1)(l)
l = Dense(10, activation='softmax')(l)

model = Model(inputs, l)

model.summary()

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_10 (InputLayer)           (None, 28, 28, 1)    0                                            
__________________________________________________________________________________________________
conv2d_74 (Conv2D)              (None, 26, 26, 8)    80          input_10[0][0]                   
__________________________________________________________________________________________________
activation_346 (Activation)     (None, 26, 26, 8)    0           conv2d_74[0][0]                  
__________________________________________________________________________________________________
batch_normalization_381 (BatchN (None, 26, 26, 8)    32          activation_346[0][0]             
__________________________________________________________________________________________________
max_pooling2d_74 (MaxPooling2D) (None, 13, 13, 8)    0           batch_normalization_381[0][0]    
__________________________________________________________________________________________________
dropout_364 (Dropout)           (None, 13, 13, 8)    0           max_pooling2d_74[0][0]           
__________________________________________________________________________________________________
separable_conv2d_67 (SeparableC (None, 11, 11, 28)   324         dropout_364[0][0]                
__________________________________________________________________________________________________
activation_347 (Activation)     (None, 11, 11, 28)   0           separable_conv2d_67[0][0]        
__________________________________________________________________________________________________
batch_normalization_382 (BatchN (None, 11, 11, 28)   112         activation_347[0][0]             
__________________________________________________________________________________________________
dropout_365 (Dropout)           (None, 11, 11, 28)   0           batch_normalization_382[0][0]    
__________________________________________________________________________________________________
separable_conv2d_68 (SeparableC (None, 11, 11, 28)   1064        dropout_365[0][0]                
                                                                 dropout_366[0][0]                
                                                                 dropout_367[0][0]                
__________________________________________________________________________________________________
activation_348 (Activation)     (None, 11, 11, 28)   0           separable_conv2d_68[0][0]        
__________________________________________________________________________________________________
batch_normalization_383 (BatchN (None, 11, 11, 28)   112         activation_348[0][0]             
__________________________________________________________________________________________________
dropout_366 (Dropout)           (None, 11, 11, 28)   0           batch_normalization_383[0][0]    
__________________________________________________________________________________________________
activation_349 (Activation)     (None, 11, 11, 28)   0           separable_conv2d_68[1][0]        
__________________________________________________________________________________________________
batch_normalization_384 (BatchN (None, 11, 11, 28)   112         activation_349[0][0]             
__________________________________________________________________________________________________
dropout_367 (Dropout)           (None, 11, 11, 28)   0           batch_normalization_384[0][0]    
__________________________________________________________________________________________________
activation_350 (Activation)     (None, 11, 11, 28)   0           separable_conv2d_68[2][0]        
__________________________________________________________________________________________________
batch_normalization_385 (BatchN (None, 11, 11, 28)   112         activation_350[0][0]             
__________________________________________________________________________________________________
dropout_368 (Dropout)           (None, 11, 11, 28)   0           batch_normalization_385[0][0]    
__________________________________________________________________________________________________
global_average_pooling2d_31 (Gl (None, 28)           0           dropout_368[0][0]                
__________________________________________________________________________________________________
dense_93 (Dense)                (None, 16)           464         global_average_pooling2d_31[0][0]
__________________________________________________________________________________________________
batch_normalization_386 (BatchN (None, 16)           64          dense_93[0][0]                   
__________________________________________________________________________________________________
dropout_369 (Dropout)           (None, 16)           0           batch_normalization_386[0][0]    
__________________________________________________________________________________________________
dense_94 (Dense)                (None, 10)           170         dropout_369[0][0]                
==================================================================================================
Total params: 2,646
Trainable params: 2,374
Non-trainable params: 272

Test score:  0.029238566553150304
Test accuracy:  0.9912

